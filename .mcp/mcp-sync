#!/usr/bin/env bash
set -euo pipefail

# MCP Unified Management Tool v2.0 - Production Ready
# Single source of truth for MCP server configurations

# Default configuration
MASTER_FILE="${HOME}/.mcp/servers.json"
REGISTRY_FILE="${HOME}/.mcp/state/generated.json"
PROFILE="${PROFILE:-full}"
TARGET="${TARGET:-all}"
CHECK_ENV="${CHECK_ENV:-on}"
EXPAND_ENV="${EXPAND_ENV:-off}"
DRY_RUN=1  # Default to dry-run for safety
QUARANTINE=0

# Target paths
declare -A TARGET_PATHS=(
    ["claude"]="./.claude/mcp.json"
    ["codex"]="${HOME}/.codex/config.toml"
    ["opencode"]="${HOME}/.config/opencode/opencode.json"
)

# Utility functions
error() {
    echo "ERROR: $*" >&2
    exit 1
}

log() {
    echo "INFO: $*" >&2
}

# Path expansion - convert ~ and $HOME to absolute paths
expand_path() {
    local path="$1"
    # Replace ~ with $HOME
    path="${path/#~/$HOME}"
    # Replace $HOME with actual home directory
    path="${path//\$HOME/$HOME}"
    echo "$path"
}

# Validate paths are absolute
validate_absolute_path() {
    local path="$1"
    [[ "$path" = /* ]] || error "Path must be absolute: $path"
}

# Registry management for tracking generated files with flock protection

# Shared flock helper function with timeout and error handling
with_registry_lock() {
    local operation="$1"
    shift
    local lock_file="${REGISTRY_FILE}.lock"
    local timeout=10
    local fd

    # Ensure lock file directory exists
    mkdir -p "$(dirname "$lock_file")"

    # Open lock file for writing (creates if doesn't exist)
    exec {fd}>"$lock_file" || {
        error "Failed to open lock file: $lock_file"
    }

    # Try to acquire exclusive lock with timeout
    if ! timeout "$timeout" flock "$fd" 2>/dev/null; then
        exec {fd}>&-  # Close file descriptor
        error "Failed to acquire registry lock within ${timeout}s (another mcp-sync process may be running)"
    fi

    # Execute the operation with lock held
    local result=0
    case "$operation" in
        "ensure")
            _ensure_registry_locked "$@" || result=$?
            ;;
        "update")
            _update_registry_locked "$@" || result=$?
            ;;
        "get_hash")
            _get_registry_hash_locked "$@" || result=$?
            ;;
        *)
            error "Unknown registry operation: $operation"
            ;;
    esac

    # Release lock and close file descriptor
    exec {fd}>&-
    return $result
}

# Internal function: ensure registry exists (called with lock held)
_ensure_registry_locked() {
    mkdir -p "$(dirname "$REGISTRY_FILE")"
    if [[ ! -f "$REGISTRY_FILE" ]]; then
        echo '{"files": {}}' > "$REGISTRY_FILE" || {
            error "Failed to initialize registry file: $REGISTRY_FILE"
        }
    fi
}

# Internal function: update registry (called with lock held)
_update_registry_locked() {
    local file="$1" sha256="$2"

    # Ensure registry exists
    _ensure_registry_locked

    local temp_registry
    temp_registry=$(mktemp) || {
        error "Failed to create temporary file for registry update"
    }

    # Set up cleanup trap for temporary file
    trap "rm -f '$temp_registry'" RETURN

    # Update registry with new entry
    if ! jq --arg path "$file" \
           --arg hash "$sha256" \
           --arg ver "v2.0" \
           --arg ts "$(date -Iseconds)" \
           '.files[$path] = {sha256: $hash, toolVersion: $ver, timestamp: $ts}' \
           "$REGISTRY_FILE" > "$temp_registry"; then
        error "Failed to update registry JSON for: $file"
    fi

    # Atomic move to replace registry file
    if ! mv "$temp_registry" "$REGISTRY_FILE"; then
        error "Failed to replace registry file: $REGISTRY_FILE"
    fi

    log "Updated registry for: $file"
}

# Internal function: get registry hash (called with lock held)
_get_registry_hash_locked() {
    local file="$1"

    # Ensure registry exists
    _ensure_registry_locked

    # Get hash from registry (output to stdout)
    jq -r --arg f "$file" '.files[$f].sha256 // "unknown"' "$REGISTRY_FILE" 2>/dev/null || {
        echo "unknown"
        return 1
    }
}

# Public API functions with flock protection
ensure_registry() {
    with_registry_lock "ensure"
}

update_registry() {
    local file="$1" sha256="$2"
    with_registry_lock "update" "$file" "$sha256"
}

get_registry_hash() {
    local file="$1"
    with_registry_lock "get_hash" "$file"
}

# Hybrid detection system for TOML (comment) and JSON (registry+hash)
detect_generated_file() {
    local file="$1"

    if [[ ! -f "$file" ]]; then
        return 1  # File doesn't exist
    fi

    case "$file" in
        *.toml)
            # TOML files: check for comment signature
            if head -5 "$file" | grep -q "Generated by mcp-sync"; then
                return 0  # Generated
            else
                return 1  # User-made or unknown
            fi
            ;;
        *.json)
            # JSON files: check registry + hash
            local current_hash expected_hash
            current_hash=$(sha256sum "$file" | cut -d' ' -f1)
            expected_hash=$(get_registry_hash "$file")

            if [[ "$current_hash" == "$expected_hash" && "$expected_hash" != "unknown" ]]; then
                return 0  # Generated and hash matches
            else
                return 1  # User-made, modified, or unknown
            fi
            ;;
        *)
            return 1  # Unknown format → User-made
            ;;
    esac
}

# Show inventory of configuration files
show_inventory() {
    echo "=== MCP Configuration Inventory ==="

    for target in "${!TARGET_PATHS[@]}"; do
        local file_path
        file_path=$(expand_path "${TARGET_PATHS[$target]}")

        if [[ -f "$file_path" ]]; then
            if detect_generated_file "$file_path"; then
                echo "GENERATED: $file_path ($target)"
            else
                echo "USER-MADE: $file_path ($target)"
            fi
        else
            echo "MISSING: $file_path ($target)"
        fi
    done
    echo ""
}

# Environment variable validation
check_env_vars() {
    local master_file="$1"

    if [[ "$CHECK_ENV" != "on" ]]; then
        return 0
    fi

    log "Checking environment variables..."

    # Extract all ${env:VAR} patterns and check if they exist
    local env_vars
    env_vars=$(jq -r '
        .. |
        select(type == "string" and test("\\$\\{env:[A-Z_][A-Z0-9_]*\\}")) |
        capture("\\$\\{env:(?<var>[A-Z_][A-Z0-9_]*)\\}").var
    ' "$master_file" 2>/dev/null | sort -u)

    for var in $env_vars; do
        if [[ -z "${!var:-}" ]]; then
            error "Required environment variable not set: $var"
        fi
    done

    log "Environment variables validated"
}

# Schema validation with enhanced checks
validate_schema() {
    local file="$1"

    log "Validating schema for $file..."

    # Check if file exists and is valid JSON
    if [[ ! -f "$file" ]]; then
        error "Master file not found: $file"
    fi

    if ! jq empty "$file" 2>/dev/null; then
        error "Invalid JSON in $file"
    fi

    # Basic structure validation
    if ! jq -e '
        (.version | type == "string") and
        (.mcpServers | type == "object") and
        (.profiles | type == "object")
    ' "$file" >/dev/null; then
        error "Basic schema validation failed for $file"
    fi

    # Validate each server individually
    local server_names
    server_names=$(jq -r '.mcpServers | keys[]' "$file")

    for server_name in $server_names; do
        if ! jq -e --arg name "$server_name" '
            .mcpServers[$name] |
            (.type | . == "stdio" or . == "sse" or . == "http") and
            (.command | type == "string") and
            (.args | type == "array" and all(.[]; type == "string")) and
            (.env | type == "object") and
            (.env | if . == {} then true else to_entries | map(.value | test("^\\$\\{env:[A-Z_][A-Z0-9_]*\\}$")) | all end) and
            ((.tags // ["all"]) | type == "array" and all(. == "all" or . == "claude" or . == "codex" or . == "opencode"))
        ' "$file" >/dev/null; then
            error "Server validation failed for: $server_name"
        fi
    done

    # Validate profiles reference existing servers
    local profiles_invalid
    profiles_invalid=$(jq -r '
        . as $root |
        .profiles | to_entries[] |
        .value[] as $server |
        select(($root.mcpServers | has($server) | not)) |
        "Profile \(.key) references unknown server: \($server)"
    ' "$file" 2>/dev/null)

    if [[ -n "$profiles_invalid" ]]; then
        error "$profiles_invalid"
    fi

    log "Schema validation passed"
}

# Expand environment variables and paths in server configurations (ultra-deterministic)
expand_server_configs() {
    local servers_json="$1"

    local expanded_result
    if [[ "$EXPAND_ENV" == "on" ]]; then
        # Expand environment variables safely - only ${env:VAR} patterns
        expanded_result=$(echo "$servers_json" | jq --argjson expand_env true '
            def expand_env_vars:
                if type == "string" then
                    gsub("\\$\\{env:(?<var>[A-Z_][A-Z0-9_]*)\\}"; env[.var] // "${env:\(.var)}")
                elif type == "object" then
                    with_entries(.value |= expand_env_vars)
                elif type == "array" then
                    map(expand_env_vars)
                else
                    .
                end;

            to_entries | map(
                .value |= expand_env_vars |
                .value.args = (.value.args | map(
                    # Expand paths starting with ~ or $HOME
                    if test("^~") then
                        sub("^~"; env.HOME)
                    elif test("^\\$HOME") then
                        sub("^\\$HOME"; env.HOME)
                    else
                        .
                    end
                ))
            ) | from_entries |
            # Ensure deterministic ordering
            to_entries | sort_by(.key) | from_entries
        ')
    else
        # No expansion, but ensure deterministic ordering
        expanded_result=$(echo "$servers_json" | jq '
            to_entries | sort_by(.key) | from_entries
        ')
    fi

    # Validate all paths in args arrays are absolute after expansion
    local server_names
    server_names=$(echo "$expanded_result" | jq -r 'keys[]')

    for server_name in $server_names; do
        local args_json
        args_json=$(echo "$expanded_result" | jq -c ".\"$server_name\".args")

        # Check each argument that looks like a file path (not NPM packages or env vars)
        # Skip NPM package names, environment variables, and command flags
        local arg
        while IFS= read -r arg; do
            # Skip if it's an NPM package (starts with @, or contains only alphanumeric/dash/underscore)
            if [[ "$arg" =~ ^@ ]] || [[ "$arg" =~ ^[a-zA-Z0-9_-]+$ ]]; then
                continue
            fi
            # Skip if it's an environment variable (contains $)
            if [[ "$arg" =~ \$ ]]; then
                continue
            fi
            # Skip if it's a command flag (starts with -)
            if [[ "$arg" =~ ^- ]]; then
                continue
            fi
            # Check if it looks like a relative file path (contains / or . but not absolute)
            if [[ "$arg" =~ (\./|\.\./) ]] || [[ "$arg" =~ ^[^/].*/ ]]; then
                error "Relative path detected in server '$server_name' args: $arg (use absolute paths or environment variables like \$HOME)"
            fi
        done < <(echo "$args_json" | jq -r '.[]')
    done

    echo "$expanded_result"
}

# Filter servers by profile and tags
filter_servers() {
    local master_file="$1"
    local profile="$2"
    local target_tags="$3"

    # Get servers for profile
    local server_list
    server_list=$(jq -r ".profiles[\"$profile\"] // empty | .[]" "$master_file")

    if [[ -z "$server_list" ]]; then
        # If profile doesn't exist, use all servers
        server_list=$(jq -r '.mcpServers | keys[]' "$master_file")
    fi

    # Filter by tags for specific targets
    local filtered_servers="{}"
    for server in $server_list; do
        local server_tags
        server_tags=$(jq -r ".mcpServers[\"$server\"].tags // [\"all\"] | @csv" "$master_file" | tr -d '"')

        # Check if server should be included for this target
        local include_server=0
        IFS=',' read -ra tags_array <<< "$server_tags"
        for tag in "${tags_array[@]}"; do
            if [[ "$tag" == "all" ]] || [[ ",$target_tags," == *",$tag,"* ]]; then
                include_server=1
                break
            fi
        done

        if [[ $include_server -eq 1 ]]; then
            local server_config
            server_config=$(jq ".mcpServers[\"$server\"]" "$master_file")
            filtered_servers=$(echo "$filtered_servers" | jq ". + {\"$server\": $server_config}")
        fi
    done

    echo "$filtered_servers"
}

# Render for Claude Code CLI (ultra-deterministic)
render_claude() {
    local servers="$1"
    echo "$servers" | jq -S '
        {mcpServers: (. | to_entries | sort_by(.key) | from_entries)}
    '
}

# Render for Codex CLI (TOML format)
render_codex() {
    local servers="$1"

    echo "# Generated by mcp-sync"
    echo ""

    # Get server names and sort them
    local server_names
    server_names=$(echo "$servers" | jq -r 'keys[]' | sort)

    for server_name in $server_names; do
        echo "[mcp_servers.$server_name]"

        # Get command
        local command
        command=$(echo "$servers" | jq -r ".\"$server_name\".command")
        echo "command = \"$command\""

        # Get args array
        local args_json
        args_json=$(echo "$servers" | jq -c ".\"$server_name\".args")
        local args_toml="["
        local first=true

        # Parse JSON array to TOML array
        local arg
        while IFS= read -r arg; do
            if [ "$first" = true ]; then
                first=false
            else
                args_toml+=", "
            fi
            # Escape quotes in the argument
            arg_escaped=${arg//\"/\\\"}
            args_toml+="\"$arg_escaped\""
        done < <(echo "$args_json" | jq -r '.[]')

        args_toml+="]"
        echo "args = $args_toml"

        # Get env if present and not empty
        local env_keys
        env_keys=$(echo "$servers" | jq -r ".\"$server_name\".env | keys[]" 2>/dev/null | sort)

        if [ -n "$env_keys" ]; then
            echo "[mcp_servers.$server_name.env]"
            for env_key in $env_keys; do
                local env_value
                env_value=$(echo "$servers" | jq -r ".\"$server_name\".env.\"$env_key\"")
                echo "$env_key = \"$env_value\""
            done
        fi

        echo ""
    done
}

# Render for OpenCode (DISABLED - 仮説実装のため暫定無効化)
# NOTE: この関数は仕様確定後に再有効化予定
# WARNING: 現在の実装は以下の未確証仮説に基づく:
#   - $schema: https://opencode.ai/config.json (根拠未提示)
#   - ルートレベルmcpマップ形式 (公式仕様未確認)
render_opencode() {
    local servers="$1"

    # Convert to OpenCode format with deterministic ordering
    echo "$servers" | jq -S '
        {
            "$schema": "https://opencode.ai/config.json",
            "mcp": (
                to_entries | sort_by(.key) | map(
                    {
                        key: .key,
                        value: {
                            "type": "local",
                            "command": ([.value.command] + .value.args),
                            "enabled": true,
                            "environment": (
                                .value.env |
                                to_entries | sort_by(.key) |
                                map({key: .key, value: .value}) |
                                from_entries
                            )
                        }
                    }
                ) | from_entries
            )
        }
    '
}

# Safe atomic write with backup and symlink protection
write_safe() {
    local target="$1"
    local content="$2"

    # Symlink protection: skip if target is a symlink
    if [[ -L "$target" ]]; then
        log "SKIP: $target is a symlink (protected from overwrite)"
        return 0
    fi

    # Create directory if it doesn't exist
    mkdir -p "$(dirname "$target")"

    # Create temporary file in same directory for atomic move
    local temp_file
    temp_file=$(mktemp -p "$(dirname "$target")" "$(basename "$target").XXXXXX")

    # Set up cleanup trap for error cases
    trap "rm -f '$temp_file'" EXIT

    echo "$content" > "$temp_file"
    chmod 600 "$temp_file"

    # Check if content is different
    if cmp -s "$temp_file" "$target" 2>/dev/null; then
        log "No changes needed for $target"
        rm -f "$temp_file"
        trap - EXIT
        return 0
    fi

    # Backup existing file if it exists and is not a symlink
    if [[ -f "$target" && ! -L "$target" ]]; then
        cp "$target" "$target.bak"
        log "Backed up $target to $target.bak"
    fi

    # Atomic move (single system call)
    mv "$temp_file" "$target"
    trap - EXIT

    log "Updated $target"
}

# Show diff between files with fallback to system diff
show_diff() {
    local old_file="$1"
    local new_file="$2"

    if [[ -f "$old_file" ]]; then
        # Try git diff first, fallback to system diff if git fails
        if ! git --no-pager diff --no-index --color -- "$old_file" "$new_file" 2>/dev/null; then
            # Git diff failed, try system diff
            if command -v diff >/dev/null 2>&1; then
                diff -u "$old_file" "$new_file" 2>/dev/null || true
            else
                # No diff available, show files separately
                echo "=== Comparison (no diff tool available) ==="
                echo "--- Old file: $old_file ---"
                cat "$old_file"
                echo ""
                echo "--- New file: $new_file ---"
                cat "$new_file"
            fi
        fi
    else
        echo "=== New file: $new_file ==="
        cat "$new_file"
    fi
}

# Check if current directory is inside a git project
is_git_project() {
    # Check if .git directory exists in current or parent directories
    local dir="$PWD"
    while [[ "$dir" != "/" ]]; do
        if [[ -d "$dir/.git" ]]; then
            return 0  # Found .git directory
        fi
        dir=$(dirname "$dir")
    done
    return 1  # No .git directory found
}

# Ultra-safe cleaning: quarantine or remove generated files
quarantine_file() {
    local file="$1"

    # Symlink protection: skip if file is a symlink
    if [[ -L "$file" ]]; then
        log "SKIP: $file is a symlink (protected from quarantine)"
        return 0
    fi

    local quarantine_dir
    quarantine_dir="$(dirname "$file")/.invalid"

    mkdir -p "$quarantine_dir"
    local base_name
    base_name=$(basename "$file")
    local quarantine_path="$quarantine_dir/$base_name.$(date +%Y%m%d-%H%M%S)"

    mv "$file" "$quarantine_path"
    log "Quarantined: $file → $quarantine_path"
}

# Safe cleanup of generated files only
clean_generated_files() {
    local action="$1"  # "remove" or "quarantine"
    local cleaned_count=0
    local preserved_count=0

    log "Starting ultra-safe cleanup (action: $action)..."

    for target in "${!TARGET_PATHS[@]}"; do
        local file_path
        file_path=$(expand_path "${TARGET_PATHS[$target]}")

        # Symlink protection: skip if target is a symlink
        if [[ -L "$file_path" ]]; then
            log "SKIP: $file_path is a symlink (protected from deletion)"
            continue
        fi

        if [[ -f "$file_path" ]]; then
            if detect_generated_file "$file_path"; then
                if [[ $DRY_RUN -eq 1 ]]; then
                    echo "WOULD CLEAN: $file_path ($target) - Generated file"
                    ((cleaned_count++))
                else
                    case "$action" in
                        quarantine)
                            quarantine_file "$file_path"
                            ((cleaned_count++))
                            ;;
                        remove)
                            rm -f "$file_path"
                            log "Removed generated file: $file_path"
                            ((cleaned_count++))
                            ;;
                    esac
                fi
            else
                echo "PRESERVED: $file_path ($target) - User-made file"
                ((preserved_count++))
            fi
        fi
    done

    # Clean backup files only if they were generated
    for target in "${!TARGET_PATHS[@]}"; do
        local file_path
        file_path=$(expand_path "${TARGET_PATHS[$target]}")
        local backup_path="$file_path.bak"

        # Symlink protection: skip if backup is a symlink
        if [[ -L "$backup_path" ]]; then
            log "SKIP: $backup_path is a symlink (protected from deletion)"
            continue
        fi

        if [[ -f "$backup_path" ]]; then
            if detect_generated_file "$backup_path"; then
                if [[ $DRY_RUN -eq 1 ]]; then
                    echo "WOULD CLEAN: $backup_path (backup) - Generated file"
                    ((cleaned_count++))
                else
                    case "$action" in
                        quarantine)
                            quarantine_file "$backup_path"
                            ((cleaned_count++))
                            ;;
                        remove)
                            rm -f "$backup_path"
                            log "Removed generated backup: $backup_path"
                            ((cleaned_count++))
                            ;;
                    esac
                fi
            else
                echo "PRESERVED: $backup_path (backup) - User-made file"
                ((preserved_count++))
            fi
        fi
    done

    # Summary
    echo ""
    echo "=== Cleanup Summary ==="
    if [[ $DRY_RUN -eq 1 ]]; then
        echo "DRY RUN: Would clean $cleaned_count files, preserve $preserved_count files"
    else
        echo "Cleaned: $cleaned_count files, Preserved: $preserved_count files"
    fi

    if [[ $cleaned_count -eq 0 && $preserved_count -eq 0 ]]; then
        log "No MCP configuration files found"
    fi
}

# Deploy to specific target (ultra-deterministic with registry tracking)
deploy_target() {
    local target="$1"
    local servers="$2"

    local target_path="${TARGET_PATHS[$target]}"
    local rendered_content

    # Apply ultra-deterministic server expansion
    local expanded_servers
    expanded_servers=$(expand_server_configs "$servers")

    case "$target" in
        claude)
            # Claude CLI出力ガード: プロジェクト境界検出
            if ! is_git_project; then
                echo "WARNING: Claude target skipped - not in a git project (.git directory not found)" >&2
                echo "INFO: Claude configuration requires being inside a git project to prevent accidental file creation" >&2
                return 0
            fi
            rendered_content=$(render_claude "$expanded_servers")
            ;;
        codex)
            rendered_content=$(render_codex "$expanded_servers")
            ;;
        opencode)
            # OpenCode暫定スキップ - 仕様確定待ち
            echo "WARNING: OpenCode target is temporarily skipped (specification pending)" >&2
            echo "INFO: OpenCode configuration will be supported once official specification is confirmed" >&2
            return 0
            ;;
        *)
            error "Unknown target: $target"
            ;;
    esac

    # Expand paths in target_path
    target_path=$(expand_path "$target_path")

    if [[ $DRY_RUN -eq 1 ]]; then
        echo "=== DRY RUN: Changes for $target ($target_path) ==="
        local temp_file
        temp_file=$(mktemp)
        echo "$rendered_content" > "$temp_file"
        show_diff "$target_path" "$temp_file"
        rm -f "$temp_file"
        echo ""
    else
        # Write with registry tracking for JSON files
        if [[ "$target_path" == *.json ]]; then
            write_safe_with_registry "$target_path" "$rendered_content"
        else
            write_safe "$target_path" "$rendered_content"
        fi
    fi
}

# Enhanced write with automatic registry tracking for JSON files
write_safe_with_registry() {
    local target="$1"
    local content="$2"

    # Use existing write_safe function
    write_safe "$target" "$content"

    # Update registry with file hash if write was successful
    if [[ -f "$target" ]]; then
        local file_hash
        file_hash=$(sha256sum "$target" | cut -d' ' -f1)
        update_registry "$target" "$file_hash"
    fi
}

# Main execution
main() {
    # Parse command line arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --profile)
                PROFILE="$2"
                shift 2
                ;;
            --target)
                TARGET="$2"
                shift 2
                ;;
            --dry-run)
                DRY_RUN=1
                shift
                ;;
            --apply)
                DRY_RUN=0
                shift
                ;;
            --quarantine)
                QUARANTINE=1
                shift
                ;;
            --inventory)
                show_inventory
                exit 0
                ;;
            --clean)
                if [[ $QUARANTINE -eq 1 ]]; then
                    clean_generated_files "quarantine"
                else
                    clean_generated_files "remove"
                fi
                exit 0
                ;;
            --check-env)
                CHECK_ENV="$2"
                shift 2
                ;;
            --expand-env)
                EXPAND_ENV="$2"
                shift 2
                ;;
            -h|--help)
                cat <<EOF
MCP Unified Management Tool v2.0 - Production Perfect

USAGE:
    mcp-sync [OPTIONS]

SAFETY OPTIONS:
    --apply             Apply changes (default: dry-run only)
    --quarantine        Move unknown files to .invalid (default: keep)
    --inventory         Show current file status and exit
    --clean             Remove/quarantine generated files only (ultra-safe)

STANDARD OPTIONS:
    --profile PROFILE   Profile to use (default: full)
    --target TARGETS    Comma-separated targets (default: all)
                       Available: claude, codex, opencode, all
                       Note: opencode is temporarily skipped (specification pending)
    --dry-run          Show changes without applying them (default)
    --check-env on|off Check environment variables (default: on)
    --expand-env on|off Expand environment variables (default: off)
    -h, --help         Show this help

EXAMPLES:
    mcp-sync --inventory                       # Show file status
    mcp-sync --dry-run                         # Preview changes (default)
    mcp-sync --apply                           # Apply changes
    mcp-sync --profile minimal --apply        # Apply minimal profile
    mcp-sync --target claude,codex --apply    # Apply to specific targets
    mcp-sync --target opencode --apply        # OpenCode target (shows warning)
    mcp-sync --quarantine --apply             # Quarantine unknown files
    mcp-sync --clean                           # Preview cleanup (dry-run)
    mcp-sync --clean --apply                   # Remove generated files
    mcp-sync --clean --quarantine --apply     # Quarantine generated files
EOF
                exit 0
                ;;
            *)
                error "Unknown option: $1"
                ;;
        esac
    done

    # Validate master file
    validate_schema "$MASTER_FILE"
    check_env_vars "$MASTER_FILE"

    # Process targets
    if [[ "$TARGET" == "all" ]]; then
        # プロジェクト境界検出によるClaude target除外判定
        if is_git_project; then
            # プロジェクト内：Claudeを含む（OpenCodeは仕様確定待ちのため暫定除外）
            TARGET="claude,codex"
            echo "INFO: --target all excludes OpenCode (specification pending)" >&2
        else
            # プロジェクト外：Claudeを除外
            TARGET="codex"
            echo "INFO: --target all excludes Claude (not in git project) and OpenCode (specification pending)" >&2
        fi
    fi

    IFS=',' read -ra TARGETS <<< "$TARGET"

    # Validate targets
    for target in "${TARGETS[@]}"; do
        if [[ ! "${TARGET_PATHS[$target]:-}" ]]; then
            error "Unknown target: $target"
        fi
    done

    if [[ $DRY_RUN -eq 1 ]]; then
        echo "=== DRY RUN MODE: No files will be modified ==="
        echo ""
    fi

    # Deploy to each target
    for target in "${TARGETS[@]}"; do
        log "Processing target: $target"

        # Filter servers for this target
        local filtered_servers
        filtered_servers=$(filter_servers "$MASTER_FILE" "$PROFILE" "$target")

        # Deploy
        deploy_target "$target" "$filtered_servers"
    done

    if [[ $DRY_RUN -eq 0 ]]; then
        log "Deployment completed successfully"
    else
        log "Dry run completed - no changes made"
    fi
}

# Run main function
main "$@"