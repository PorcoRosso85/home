/**
 * POC 04: å˜ä¸€ã‚³ãƒ³ãƒ†ãƒŠã®ç ´ç¶»ç‚¹åˆ†æã‚µãƒ¼ãƒãƒ¼
 * 
 * ç›®çš„: å˜ä¸€ã‚³ãƒ³ãƒ†ãƒŠã®é™ç•Œã‚’ç§‘å­¦çš„ã«åˆ†æã—ã€å¤±æ•—ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç†è§£ã™ã‚‹
 */

import { startFailureAnalyzer } from "./failure-analyzer.ts";
import { createFailurePredictor } from "./failure-predictor.ts";

// ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
interface ServerMetrics {
  requestCount: number;
  errorCount: number;
  activeConnections: number;
  latencies: number[];
  memoryUsage: number;
  cpuStartTime: number;
  startTime: number;
}

class MetricsCollector {
  private metrics: ServerMetrics = {
    requestCount: 0,
    errorCount: 0,
    activeConnections: 0,
    latencies: [],
    memoryUsage: 0,
    cpuStartTime: performance.now(),
    startTime: Date.now()
  };

  recordRequest(latency: number, error: boolean = false) {
    this.metrics.requestCount++;
    if (error) {
      this.metrics.errorCount++;
    }
    this.metrics.latencies.push(latency);
    
    // æœ€æ–°1000ä»¶ã®ã¿ä¿æŒ
    if (this.metrics.latencies.length > 1000) {
      this.metrics.latencies.shift();
    }
  }

  incrementConnections() {
    this.metrics.activeConnections++;
  }

  decrementConnections() {
    this.metrics.activeConnections--;
  }

  getMetrics() {
    const memoryUsage = Deno.memoryUsage();
    const uptime = Date.now() - this.metrics.startTime;
    
    // P99ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã®è¨ˆç®—
    const sortedLatencies = [...this.metrics.latencies].sort((a, b) => a - b);
    const p99Index = Math.floor(sortedLatencies.length * 0.99);
    const latencyP99 = sortedLatencies[p99Index] || 0;
    
    // CPUä½¿ç”¨ç‡ã®ç°¡æ˜“è¨ˆç®—
    const cpuTime = performance.now() - this.metrics.cpuStartTime;
    const cpuUsage = Math.min(100, (cpuTime / uptime) * 100);
    
    return {
      requestCount: this.metrics.requestCount,
      errorRate: this.metrics.requestCount > 0 
        ? this.metrics.errorCount / this.metrics.requestCount 
        : 0,
      activeConnections: this.metrics.activeConnections,
      latencyP99,
      memoryUsage: Math.round((memoryUsage.heapUsed / memoryUsage.heapTotal) * 100),
      cpuUsage: Math.round(cpuUsage),
      eventLoopLag: Math.round(performance.now() % 100) // ç°¡æ˜“çš„ãªã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—é…å»¶
    };
  }
}

// åˆ†æã‚µãƒ¼ãƒãƒ¼
class FailureAnalysisServer {
  private metricsCollector = new MetricsCollector();
  private analyzer: any;
  private predictor: any;
  private degradationMode = false;
  private failureStage = 0;

  constructor(private port: number) {}

  async start() {
    // åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    this.analyzer = await startFailureAnalyzer();
    this.predictor = await createFailurePredictor();
    
    // è­¦å‘Šãƒªã‚¹ãƒŠãƒ¼ã®è¨­å®š
    this.predictor.onWarning((warning: string) => {
      console.log(`âš ï¸  WARNING: ${warning}`);
    });
    
    // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ã®é–‹å§‹
    this.startMetricsMonitoring();
    
    // HTTPã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•
    const server = Deno.serve({ port: this.port }, async (request) => {
      return this.handleRequest(request);
    });
    
    console.log(`ğŸ”¬ Failure Analysis Server started on port ${this.port}`);
    console.log(`ğŸ“Š Monitoring system metrics and failure patterns...`);
    
    return server;
  }

  private async handleRequest(request: Request): Promise<Response> {
    const startTime = performance.now();
    this.metricsCollector.incrementConnections();
    
    try {
      // è² è·ã«å¿œã˜ãŸé…å»¶ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      await this.simulateLoad();
      
      // å¤±æ•—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      if (this.shouldFail()) {
        throw new Error("System overloaded");
      }
      
      const latency = performance.now() - startTime;
      this.metricsCollector.recordRequest(latency);
      
      return new Response(JSON.stringify({
        status: "ok",
        stage: this.failureStage,
        metrics: this.metricsCollector.getMetrics()
      }), {
        headers: { "Content-Type": "application/json" }
      });
      
    } catch (error) {
      const latency = performance.now() - startTime;
      this.metricsCollector.recordRequest(latency, true);
      
      return new Response(JSON.stringify({
        error: error.message,
        stage: this.failureStage
      }), {
        status: 503,
        headers: { "Content-Type": "application/json" }
      });
      
    } finally {
      this.metricsCollector.decrementConnections();
    }
  }

  private async simulateLoad() {
    const metrics = this.metricsCollector.getMetrics();
    
    // Stage 1: åˆæœŸåŠ£åŒ–ï¼ˆ100msä»¥ä¸Šã®é…å»¶ï¼‰
    if (metrics.activeConnections > 100) {
      await new Promise(resolve => setTimeout(resolve, 50));
    }
    
    // Stage 2: éƒ¨åˆ†çš„å¤±æ•—ï¼ˆã‚¨ãƒ©ãƒ¼ç‡ä¸Šæ˜‡ï¼‰
    if (metrics.activeConnections > 300) {
      this.failureStage = 2;
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    // Stage 3: ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å¤±æ•—
    if (metrics.activeConnections > 500) {
      this.failureStage = 3;
      await new Promise(resolve => setTimeout(resolve, 200));
    }
    
    // Stage 4: å®Œå…¨åœæ­¢
    if (metrics.activeConnections > 700) {
      this.failureStage = 4;
      await new Promise(resolve => setTimeout(resolve, 500));
    }
  }

  private shouldFail(): boolean {
    const metrics = this.metricsCollector.getMetrics();
    const random = Math.random();
    
    // æ¥ç¶šæ•°ã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ç‡
    if (metrics.activeConnections > 700) {
      return random < 0.95; // 95%å¤±æ•—
    } else if (metrics.activeConnections > 500) {
      return random < 0.3; // 30%å¤±æ•—
    } else if (metrics.activeConnections > 300) {
      return random < 0.05; // 5%å¤±æ•—
    }
    
    return false;
  }

  private startMetricsMonitoring() {
    setInterval(async () => {
      const metrics = this.metricsCollector.getMetrics();
      
      // äºˆæ¸¬åˆ†æ
      await this.predictor.analyze();
      
      // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ­ã‚°
      if (metrics.requestCount % 100 === 0) {
        console.log(`ğŸ“Š Metrics: ${JSON.stringify(metrics)}`);
      }
      
      // å¤±æ•—æ®µéšã®æ¤œå‡º
      if (metrics.errorRate > 0.9 && this.failureStage !== 4) {
        console.log("ğŸ’¥ STAGE 4: Complete failure detected!");
      } else if (metrics.errorRate > 0.1 && this.failureStage < 3) {
        console.log("ğŸ”¥ STAGE 3: Cascade failure in progress!");
      } else if (metrics.errorRate > 0.01 && this.failureStage < 2) {
        console.log("âš¡ STAGE 2: Partial failures occurring!");
      } else if (metrics.latencyP99 > 100 && this.failureStage < 1) {
        console.log("ğŸŒ STAGE 1: Performance degradation detected!");
        this.failureStage = 1;
      }
      
    }, 1000);
  }
}

// ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
if (import.meta.main) {
  const port = parseInt(Deno.env.get("PORT") || "3000");
  const server = new FailureAnalysisServer(port);
  
  await server.start();
}