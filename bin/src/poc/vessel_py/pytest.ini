[pytest]
# Test discovery patterns
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = .
norecursedirs = .git .tox dist build *.egg __pycache__ .cache .venv venv

# Output formatting
addopts = 
    # Verbose output with test names
    -v
    # Show local variables in tracebacks
    -l
    # Show summary of all test outcomes
    -ra
    # Capture output only on failure
    --capture=no
    # Show extra test summary info
    --tb=short
    # Strict markers (fail on unknown markers)
    --strict-markers
    # Disable warnings summary
    --disable-warnings
    # Suppress nix warnings
    -p no:warnings
    # Show durations of slowest tests
    --durations=10
    # Color output
    --color=yes

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Markers definition
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    vessel: marks tests specific to vessel framework
    pipeline: marks tests for pipeline functionality
    data: marks tests for data vessel functionality
    structured: marks tests for structured vessel functionality
    logging: marks tests for logging functionality
    error_handling: marks tests for error handling
    skip: skip test execution
    parametrize: parametrized test cases

# Coverage options (if pytest-cov is installed)
# Uncomment to enable coverage reporting
# addopts = --cov=. --cov-report=term-missing --cov-report=html

# Timeout options (if pytest-timeout is installed)
# Uncomment to set global timeout
# timeout = 300

# Parallel execution (if pytest-xdist is installed)
# Uncomment to run tests in parallel
# addopts = -n auto

# Environment variables for tests
# Can be accessed via os.environ in tests
[pytest:env]
VESSEL_TEST_MODE = true