/**
 * ç‰¹æ€§ãƒ†ã‚¹ãƒˆï¼ˆFeathersæµï¼‰
 * ç¾åœ¨ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å‹•ä½œã‚’è¨˜éŒ²ãƒ»ä¿è­·ã™ã‚‹ãŸã‚ã®ãƒ†ã‚¹ãƒˆ
 * 
 * ç›®çš„ï¼šãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å‰ã«ç¾åœ¨ã®æŒ¯ã‚‹èˆã„ã‚’å®Œå…¨ã«ä¿è­·ã™ã‚‹
 * æ‰‹æ³•ï¼šå®Ÿéš›ã®å‹•ä½œçµæœã‚’"æ­£ã—ã„æŒ¯ã‚‹èˆã„"ã¨ã—ã¦è¨˜éŒ²
 * 
 * @see bin/docs/conventions/tdd_process.md - ãƒ‘ã‚¿ãƒ¼ãƒ³B: æ—¢å­˜ã‚³ãƒ¼ãƒ‰æ”¹ä¿®TDDï¼ˆFeathersæµï¼‰
 */

import { describe, expect, it, beforeAll, afterAll } from 'bun:test'
import { exec } from 'child_process'
import { promisify } from 'util'
import { readFile } from 'fs/promises'
import { join } from 'path'

const execAsync = promisify(exec)

describe('Characterization Tests - ç¾åœ¨ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å‹•ä½œã®ä¿è­·', () => {
  let goldenMasterData: any
  let currentOutput: any

  beforeAll(async () => {
    // ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    try {
      const goldenPath = join(__dirname, 'golden-master.json')
      const goldenContent = await readFile(goldenPath, 'utf-8')
      goldenMasterData = JSON.parse(goldenContent)
    } catch (error) {
      console.error('âš ï¸  Golden master not found - will capture current behavior')
    }
  })

  it('ç¾åœ¨ã®main.tsã®å‹•ä½œã‚’è¨˜éŒ²ã™ã‚‹ï¼ˆCHARACTERIZEï¼‰', async () => {
    // ç¾åœ¨ã®å®Ÿè£…ã‚’å®Ÿè¡Œ
    const { stdout, stderr } = await execAsync('bun run src/main.ts', {
      cwd: process.cwd(),
      env: { ...process.env, CI: 'true' } // CIç’°å¢ƒã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    })

    // JSONå‡ºåŠ›ã‚’æŠ½å‡º
    const jsonMatch = stdout.match(/ğŸ“Š Results:[\s\S]*?(\[[\s\S]*?\])/m)
    if (jsonMatch) {
      currentOutput = JSON.parse(jsonMatch[1])
    }

    // åŸºæœ¬çš„ãªæ§‹é€ æ¤œè¨¼
    expect(Array.isArray(currentOutput)).toBe(true)
    expect(currentOutput.length).toBeGreaterThan(0)

    // å„è¦ç´ ã®æ§‹é€ ã‚’æ¤œè¨¼
    currentOutput.forEach((item: any) => {
      expect(item).toHaveProperty('source')
      expect(item).toHaveProperty('company_name')
      expect(item).toHaveProperty('title')
      expect(item).toHaveProperty('url')
      expect(item).toHaveProperty('scraped_at')
    })

    console.log(`âœ… Captured ${currentOutput.length} articles`)
  })

  it('120è¨˜äº‹ã®å–å¾—å‹•ä½œã‚’ä¿è­·ã™ã‚‹', async () => {
    // å®Ÿè¡Œæ™‚ã®è¨˜äº‹æ•°ã‚’ç¢ºèª
    expect(currentOutput.length).toBe(120)
    
    // PR_TIMESã‚½ãƒ¼ã‚¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    const prTimesArticles = currentOutput.filter((item: any) => 
      item.source === 'PR_TIMES'
    )
    expect(prTimesArticles.length).toBe(120)
  })

  it('ä¼æ¥­åæŠ½å‡ºã®ç¾åœ¨ã®ç²¾åº¦ã‚’è¨˜éŒ²ã™ã‚‹', async () => {
    // ä¼æ¥­åãŒæŠ½å‡ºã§ãã¦ã„ã‚‹è¨˜äº‹æ•°ã‚’ç¢ºèª
    const withCompanyName = currentOutput.filter((item: any) => 
      item.company_name && item.company_name !== '' && item.company_name !== null
    )
    
    const extractionRate = (withCompanyName.length / currentOutput.length) * 100
    
    // ç¾åœ¨ã®å®Ÿè£…ã®å®Ÿéš›ã®æŠ½å‡ºç‡ã‚’è¨˜éŒ²ï¼ˆæ”¹å–„ãŒå¿…è¦ï¼‰
    console.log(`ğŸ“Š Company name extraction rate: ${extractionRate.toFixed(1)}%`)
    
    // ç¾åœ¨ã®å®Ÿè£…ã¯0%ã ãŒã€ã“ã‚ŒãŒç¾åœ¨ã®å‹•ä½œã¨ã—ã¦è¨˜éŒ²
    expect(extractionRate).toBe(0)
  })

  it('ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ãŒæ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ä¿è­·ã™ã‚‹', async () => {
    // ç¾åœ¨ã®å®Ÿè£…ã§ã¯ç‰¹å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è¨˜äº‹ãŒå–å¾—ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    // å®Ÿéš›ã®çµæœã«åŸºã¥ã„ã¦è¨˜éŒ²
    const hasArticles = currentOutput && currentOutput.length > 0
    expect(hasArticles).toBe(true)
    
    // ã‚¿ã‚¤ãƒˆãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
    const titlesExist = currentOutput.every((item: any) => 
      item.title && typeof item.title === 'string'
    )
    expect(titlesExist).toBe(true)
    
    console.log(`ğŸ“ Sample titles: ${currentOutput.slice(0, 3).map((item: any) => item.title).join(', ')}`)
  })

  it('å‡ºåŠ›å½¢å¼ã®ä¸€è²«æ€§ã‚’ä¿è­·ã™ã‚‹', () => {
    // ã™ã¹ã¦ã®è¨˜äº‹ãŒåŒã˜å½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    const requiredFields = ['source', 'company_name', 'title', 'url', 'scraped_at']
    
    currentOutput.forEach((item: any) => {
      requiredFields.forEach(field => {
        expect(item).toHaveProperty(field)
      })
      
      // ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
      expect(typeof item.source).toBe('string')
      expect(typeof item.title).toBe('string')
      expect(typeof item.url).toBe('string')
      expect(typeof item.scraped_at).toBe('string')
      
      // scraped_atãŒæœ‰åŠ¹ãªISOæ—¥ä»˜å½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
      expect(() => new Date(item.scraped_at)).not.toThrow()
    })
  })

  it('URLã®æœ‰åŠ¹æ€§ã‚’ä¿è­·ã™ã‚‹', () => {
    // ã™ã¹ã¦ã®URLãŒæœ‰åŠ¹ãªå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    currentOutput.forEach((item: any) => {
      expect(item.url).toMatch(/^https?:\/\//)
      
      // PR TIMESã®URLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª
      if (item.source === 'PR_TIMES') {
        expect(item.url).toContain('prtimes.jp')
      }
    })
  })

  afterAll(async () => {
    // ãƒ†ã‚¹ãƒˆçµæœã‚’ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒã‚¹ã‚¿ãƒ¼ã¨ã—ã¦ä¿å­˜ï¼ˆåˆå›å®Ÿè¡Œæ™‚ã®ã¿ï¼‰
    if (!goldenMasterData && currentOutput) {
      const goldenPath = join(__dirname, 'golden-master-characterization.json')
      await Bun.write(goldenPath, JSON.stringify({
        capturedAt: new Date().toISOString(),
        articleCount: currentOutput.length,
        extractionRate: (currentOutput.filter((item: any) => item.company_name).length / currentOutput.length) * 100,
        sample: currentOutput.slice(0, 5) // ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦æœ€åˆã®5ä»¶ã‚’ä¿å­˜
      }, null, 2))
      
      console.log('ğŸ“ Characterization data saved for future reference')
    }
  })
})

/**
 * ä¾å­˜æ€§æ³¨å…¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆæº–å‚™
 * æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨ã™ã‚‹é«˜éšé–¢æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åŸºç¤
 */
describe('Characterization - ä¾å­˜æ€§ã®è­˜åˆ¥', () => {
  it('ç¾åœ¨ã®ä¾å­˜é–¢ä¿‚ã‚’æ˜ç¢ºåŒ–ã™ã‚‹', () => {
    // ç¾åœ¨ã®ä¾å­˜é–¢ä¿‚ã‚’æ–‡æ›¸åŒ–
    const dependencies = {
      browser: 'puppeteer-core/chromium',
      scraper: 'ScraperFactory.createPRTimesScraper',
      config: 'getConfig from variables.ts',
      output: 'console.log (JSON.stringify)'
    }
    
    // ä¾å­˜é–¢ä¿‚ãŒæ˜ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    expect(Object.keys(dependencies)).toHaveLength(4)
    
    console.log('ğŸ“‹ Identified dependencies:', dependencies)
  })

  it('ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ç¾åœ¨ã®å½¢ã‚’è¨˜éŒ²ã™ã‚‹', () => {
    // ç¾åœ¨ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãŒæœŸå¾…ã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    const currentInterface = {
      methods: ['scrape'],
      inputs: ['browser', 'keyword'],
      outputs: ['ScrapedResult[]'],
      asyncMethods: ['scrape']
    }
    
    expect(currentInterface.methods).toContain('scrape')
    expect(currentInterface.asyncMethods).toContain('scrape')
    
    console.log('ğŸ“ Current scraper interface:', currentInterface)
  })
})