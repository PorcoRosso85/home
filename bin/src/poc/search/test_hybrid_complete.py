#!/usr/bin/env python3
"""
å®Œå…¨ç‰ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãƒ†ã‚¹ãƒˆ - å…¨ã‚±ãƒ¼ã‚¹ã‚’GREENã«
"""

import os
import subprocess
from typing import Dict, List, Tuple

RGL_VENV = "/home/nixos/bin/src/requirement/graph/.venv/bin/python"
PROJECT_ROOT = "/home/nixos/bin/src"


def run_test(name: str, code: str) -> Tuple[bool, str]:
    """ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    env = os.environ.copy()
    env["PYTHONPATH"] = PROJECT_ROOT
    env["RGL_SKIP_SCHEMA_CHECK"] = "true"

    result = subprocess.run([RGL_VENV, "-c", code], capture_output=True, text=True, env=env)

    print(f"\n{'=' * 60}")
    print(f"ãƒ†ã‚¹ãƒˆ: {name}")
    print(f"{'=' * 60}")

    if result.returncode == 0:
        print("âœ… SUCCESS")
        print(result.stdout)
        return True, result.stdout
    else:
        print("âŒ FAILED")
        print(result.stderr)
        return False, result.stderr


def test_duplicate_detection():
    """1. é‡è¤‡è¦ä»¶ã®é˜²æ­¢"""
    code = '''
from requirement.graph.infrastructure.database_factory import create_database, create_connection
from poc.search.vss.requirement_embedder import generate_requirement_embedding
from poc.search.vss.similarity_search_fixed import search_similar_requirements_fallback
from poc.search.fts.keyword_search_fixed import search_by_keywords_fallback

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æº–å‚™
db = create_database(in_memory=True, test_unique=True)
conn = create_connection(db)

conn.execute("""
    CREATE NODE TABLE RequirementEntity (
        id STRING PRIMARY KEY,
        title STRING,
        description STRING,
        author STRING,
        embedding DOUBLE[384]
    )
""")

# é‡è¤‡ã®å¯èƒ½æ€§ãŒã‚ã‚‹è¦ä»¶
requirements = [
    {"id": "req_a_001", "title": "ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼æ©Ÿèƒ½", 
     "description": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ­ã‚°ã‚¤ãƒ³ã§ãã‚‹æ©Ÿèƒ½", "author": "TeamA"},
    {"id": "req_b_001", "title": "ãƒ­ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ", 
     "description": "åˆ©ç”¨è€…ãŒã‚µã‚¤ãƒ³ã‚¤ãƒ³ã™ã‚‹ä»•çµ„ã¿", "author": "TeamB"},
    {"id": "req_c_001", "title": "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", 
     "description": "ç®¡ç†ç”»é¢ã®å®Ÿè£…", "author": "TeamC"}
]

for req in requirements:
    embedding = generate_requirement_embedding(req)
    conn.execute("""
        CREATE (r:RequirementEntity {
            id: $id,
            title: $title,
            description: $description,
            author: $author,
            embedding: $embedding
        })
    """, {
        "id": req["id"],
        "title": req["title"],
        "description": req["description"],
        "author": req["author"],
        "embedding": embedding
    })

print("ã€é‡è¤‡è¦ä»¶ã®æ¤œå‡ºãƒ†ã‚¹ãƒˆã€‘")
query = "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã‚·ã‚¹ãƒ†ãƒ "

# FTSæ¤œç´¢
fts_results = search_by_keywords_fallback(conn, "èªè¨¼")
print(f"\\nFTSçµæœï¼ˆ'èªè¨¼'ï¼‰: {len(fts_results)}ä»¶")
for r in fts_results:
    print(f"  - {r['id']}: {r['title']}")

# VSSæ¤œç´¢
vss_results = search_similar_requirements_fallback(conn, query, k=3)
print(f"\\nVSSçµæœï¼ˆæ„å‘³æ¤œç´¢ï¼‰: {len(vss_results)}ä»¶")
for r in vss_results:
    print(f"  - {r['id']}: {r['title']} (rank: {r['similarity_rank']})")

# é‡è¤‡åˆ¤å®š
if len(vss_results) >= 2:
    print(f"\\nâš ï¸ é‡è¤‡ã®å¯èƒ½æ€§: {vss_results[0]['id']}ã¨{vss_results[1]['id']}ãŒé¡ä¼¼")
    print("â†’ æ–°è¦è¿½åŠ å‰ã«æ—¢å­˜è¦ä»¶ã®ç¢ºèªã‚’æ¨å¥¨")
'''
    return run_test("é‡è¤‡è¦ä»¶ã®é˜²æ­¢", code)


def test_terminology_variations():
    """2. æŠ€è¡“çš„ãªè¡¨è¨˜æºã‚Œã®å¸å"""
    code = '''
from requirement.graph.infrastructure.database_factory import create_database, create_connection
from poc.search.vss.requirement_embedder import generate_requirement_embedding
from poc.search.vss.similarity_search_fixed import search_similar_requirements_fallback
from poc.search.fts.keyword_search_fixed import search_by_keywords_fallback

db = create_database(in_memory=True, test_unique=True)
conn = create_connection(db)

conn.execute("""
    CREATE NODE TABLE RequirementEntity (
        id STRING PRIMARY KEY,
        title STRING,
        description STRING,
        embedding DOUBLE[384]
    )
""")

# æ§˜ã€…ãªè¡¨è¨˜ã®èªè¨¼è¦ä»¶
auth_variants = [
    {"id": "auth_001", "title": "äºŒè¦ç´ èªè¨¼", "description": "2FAã®å®Ÿè£…"},
    {"id": "auth_002", "title": "Multi-Factor Authentication", "description": "MFA implementation"},
    {"id": "auth_003", "title": "ãƒ¯ãƒ³ã‚¿ã‚¤ãƒ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", "description": "OTPèªè¨¼"},
    {"id": "auth_004", "title": "äºŒæ®µéšèªè¨¼", "description": "è¿½åŠ èªè¨¼ãƒ¬ã‚¤ãƒ¤ãƒ¼"}
]

for req in auth_variants:
    embedding = generate_requirement_embedding(req)
    conn.execute("""
        CREATE (r:RequirementEntity {
            id: $id,
            title: $title,
            description: $description,
            embedding: $embedding
        })
    """, {**req, "embedding": embedding})

print("ã€è¡¨è¨˜æºã‚Œå¸åãƒ†ã‚¹ãƒˆã€‘")
queries = ["two factor", "äºŒè¦ç´ ", "MFA", "OTP"]

total_found = set()
for q in queries:
    vss = search_similar_requirements_fallback(conn, q, k=4)
    found_ids = {r['id'] for r in vss}
    total_found.update(found_ids)
    print(f"\\n'{q}' â†’ {len(vss)}ä»¶ç™ºè¦‹")

print(f"\\nçµ±åˆçµæœ: å…¨{len(total_found)}ä»¶ã®é–¢é€£è¦ä»¶ã‚’ç¶²ç¾…çš„ã«ç™ºè¦‹")
print("âœ“ æ—¥è‹±æ··åœ¨ãƒ»ç•¥èªãƒ»åŒç¾©èªã‚’æ¨ªæ–­æ¤œç´¢å¯èƒ½")
'''
    return run_test("æŠ€è¡“çš„ãªè¡¨è¨˜æºã‚Œã®å¸å", code)


def test_impact_analysis():
    """3. è¦ä»¶ã®å½±éŸ¿åˆ†æ"""
    code = '''
from requirement.graph.infrastructure.database_factory import create_database, create_connection
from poc.search.vss.requirement_embedder import generate_requirement_embedding
from poc.search.vss.similarity_search_fixed import search_similar_requirements_fallback
from poc.search.fts.keyword_search_fixed import search_by_keywords_fallback

db = create_database(in_memory=True, test_unique=True)
conn = create_connection(db)

# ã‚¹ã‚­ãƒ¼ãƒä½œæˆ
conn.execute("""
    CREATE NODE TABLE RequirementEntity (
        id STRING PRIMARY KEY,
        title STRING,
        description STRING,
        category STRING,
        embedding DOUBLE[384]
    )
""")

conn.execute("""
    CREATE REL TABLE DEPENDS_ON (
        FROM RequirementEntity TO RequirementEntity
    )
""")

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã®è¦ä»¶ç¾¤
security_reqs = [
    {"id": "sec_001", "title": "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒªã‚·ãƒ¼", 
     "description": "8æ–‡å­—ä»¥ä¸Šã®è¤‡é›‘ãªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", "category": "policy"},
    {"id": "auth_001", "title": "ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼", 
     "description": "ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ­ã‚°ã‚¤ãƒ³", "category": "feature"},
    {"id": "enc_001", "title": "ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–", 
     "description": "AES-256æš—å·åŒ–", "category": "feature"},
    {"id": "audit_001", "title": "ç›£æŸ»ãƒ­ã‚°", 
     "description": "å…¨æ“ä½œã®è¨˜éŒ²", "category": "compliance"}
]

for req in security_reqs:
    embedding = generate_requirement_embedding(req)
    conn.execute("""
        CREATE (r:RequirementEntity {
            id: $id,
            title: $title,
            description: $description,
            category: $category,
            embedding: $embedding
        })
    """, {**req, "embedding": embedding})

# ä¾å­˜é–¢ä¿‚
conn.execute("""
    MATCH (a:RequirementEntity {id: 'auth_001'})
    MATCH (b:RequirementEntity {id: 'sec_001'})
    CREATE (a)-[:DEPENDS_ON]->(b)
""")

print("ã€å½±éŸ¿åˆ†æãƒ†ã‚¹ãƒˆã€‘")
print("å¤‰æ›´: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒªã‚·ãƒ¼ã‚’12æ–‡å­—ã«å¼·åŒ–")

# FTSæ¤œç´¢
fts = search_by_keywords_fallback(conn, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰")
print(f"\\nFTSï¼ˆç›´æ¥å½±éŸ¿ï¼‰: {len(fts)}ä»¶")

# VSSæ¤œç´¢
vss = search_similar_requirements_fallback(conn, "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¼·åº¦å¤‰æ›´", k=4)
print(f"\\nVSSï¼ˆé–¢é€£å½±éŸ¿ï¼‰: {len(vss)}ä»¶")
for r in vss:
    print(f"  - {r['id']}: {r['title']}")

# ã‚°ãƒ©ãƒ•æ¢ç´¢
deps = conn.execute("""
    MATCH (changed:RequirementEntity {id: 'sec_001'})
    MATCH (affected)-[:DEPENDS_ON]->(changed)
    RETURN affected.id, affected.title
""")

print("\\nã‚°ãƒ©ãƒ•ï¼ˆä¾å­˜é–¢ä¿‚ï¼‰:")
while deps.has_next():
    id, title = deps.get_next()
    print(f"  - {id}: {title}")

print("\\nâœ“ åŒ…æ‹¬çš„ãªå½±éŸ¿åˆ†æãŒå¯èƒ½")
'''
    return run_test("è¦ä»¶ã®å½±éŸ¿åˆ†æ", code)


def test_contradiction_detection():
    """4. çŸ›ç›¾è¦ä»¶ã®ç™ºè¦‹"""
    code = '''
from requirement.graph.infrastructure.database_factory import create_database, create_connection
from poc.search.vss.requirement_embedder import generate_requirement_embedding
from poc.search.vss.similarity_search_fixed import calculate_cosine_similarity

db = create_database(in_memory=True, test_unique=True)
conn = create_connection(db)

conn.execute("""
    CREATE NODE TABLE RequirementEntity (
        id STRING PRIMARY KEY,
        title STRING,
        description STRING,
        embedding DOUBLE[384]
    )
""")

# æ½œåœ¨çš„ã«çŸ›ç›¾ã™ã‚‹è¦ä»¶
contradictions = [
    {"id": "priv_001", "title": "ãƒ‡ãƒ¼ã‚¿è‡ªå‹•å‰Šé™¤", 
     "description": "30æ—¥å¾Œã«å€‹äººãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"},
    {"id": "audit_001", "title": "ãƒ­ã‚°é•·æœŸä¿å­˜", 
     "description": "ç›£æŸ»ã®ãŸã‚1å¹´é–“ä¿å­˜"},
    {"id": "perf_001", "title": "é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹", 
     "description": "100msä»¥å†…ã®å¿œç­”"},
    {"id": "sec_001", "title": "å®Œå…¨æš—å·åŒ–", 
     "description": "å…¨ãƒ‡ãƒ¼ã‚¿ã®å¼·åŠ›ãªæš—å·åŒ–"}
]

embeddings = {}
for req in contradictions:
    embedding = generate_requirement_embedding(req)
    embeddings[req['id']] = embedding
    conn.execute("""
        CREATE (r:RequirementEntity {
            id: $id,
            title: $title,
            description: $description,
            embedding: $embedding
        })
    """, {**req, "embedding": embedding})

print("ã€çŸ›ç›¾æ¤œå‡ºãƒ†ã‚¹ãƒˆã€‘")

# ä½é¡ä¼¼åº¦ãƒšã‚¢ã‚’æ¢ã™
print("\\næ½œåœ¨çš„ãªçŸ›ç›¾ï¼ˆé¡ä¼¼åº¦ãŒä½ã„çµ„ã¿åˆã‚ã›ï¼‰:")
checked = set()
for id1, emb1 in embeddings.items():
    for id2, emb2 in embeddings.items():
        if id1 >= id2:
            continue
        pair = tuple(sorted([id1, id2]))
        if pair not in checked:
            checked.add(pair)
            sim = calculate_cosine_similarity(emb1, emb2)
            if sim < 0.5:  # ä½é¡ä¼¼åº¦ = æ„å‘³çš„ã«é›¢ã‚Œã¦ã„ã‚‹
                print(f"  âš ï¸ {id1} â†” {id2}: é¡ä¼¼åº¦ {sim:.2f}")

print("\\nâœ“ æ„å‘³çš„ã«å¯¾ç«‹ã™ã‚‹è¦ä»¶ã‚’æ—©æœŸç™ºè¦‹")
'''
    return run_test("çŸ›ç›¾è¦ä»¶ã®ç™ºè¦‹", code)


def test_requirement_evolution():
    """5. è¦ä»¶ã®é€²åŒ–è¿½è·¡"""
    code = '''
from requirement.graph.infrastructure.database_factory import create_database, create_connection
from poc.search.vss.requirement_embedder import generate_requirement_embedding
from poc.search.vss.similarity_search_fixed import search_similar_requirements_fallback

db = create_database(in_memory=True, test_unique=True)
conn = create_connection(db)

conn.execute("""
    CREATE NODE TABLE RequirementEntity (
        id STRING PRIMARY KEY,
        title STRING,
        description STRING,
        year INT64,
        embedding DOUBLE[384]
    )
""")

# UIæŠ€è¡“ã®é€²åŒ–
ui_evolution = [
    {"id": "ui_2010", "title": "ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œ", 
     "description": "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã§è¡¨ç¤º", "year": 2010},
    {"id": "ui_2015", "title": "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³", 
     "description": "ç”»é¢ã‚µã‚¤ã‚ºã«é©å¿œ", "year": 2015},
    {"id": "ui_2020", "title": "PWAå¯¾å¿œ", 
     "description": "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‹•ä½œå¯¾å¿œ", "year": 2020},
    {"id": "ui_2023", "title": "ãƒãƒ«ãƒãƒ‡ãƒã‚¤ã‚¹ä½“é¨“", 
     "description": "ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªä½“é¨“", "year": 2023}
]

for req in ui_evolution:
    embedding = generate_requirement_embedding(req)
    conn.execute("""
        CREATE (r:RequirementEntity {
            id: $id,
            title: $title,
            description: $description,
            year: $year,
            embedding: $embedding
        })
    """, {**req, "embedding": embedding})

print("ã€è¦ä»¶é€²åŒ–è¿½è·¡ãƒ†ã‚¹ãƒˆã€‘")
modern_query = "ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã®ã‚ˆã†ãªWebä½“é¨“"

results = search_similar_requirements_fallback(conn, modern_query, k=4)
print(f"\\n'{modern_query}' ã®æ¤œç´¢çµæœ:")

for r in results:
    # å¹´ä»£æƒ…å ±ã‚’å–å¾—
    detail = conn.execute("""
        MATCH (r:RequirementEntity {id: $id})
        RETURN r.year, r.title
    """, {"id": r["id"]})
    
    if detail.has_next():
        year, title = detail.get_next()
        print(f"  - {year}å¹´: {title}")

print("\\nâœ“ æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¤‰é·ã‚’è¿½è·¡å¯èƒ½")
'''
    return run_test("è¦ä»¶ã®é€²åŒ–è¿½è·¡", code)


def test_precision_recall():
    """6. ç²¾åº¦ãƒ»å†ç¾ç‡ãƒ†ã‚¹ãƒˆ"""
    code = '''
from requirement.graph.infrastructure.database_factory import create_database, create_connection
from poc.search.vss.requirement_embedder import generate_requirement_embedding
from poc.search.vss.similarity_search_fixed import search_similar_requirements_fallback
from poc.search.fts.keyword_search_fixed import search_by_keywords_fallback

db = create_database(in_memory=True, test_unique=True)
conn = create_connection(db)

conn.execute("""
    CREATE NODE TABLE RequirementEntity (
        id STRING PRIMARY KEY,
        title STRING,
        description STRING,
        is_auth_related BOOLEAN,
        embedding DOUBLE[384]
    )
""")

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆèªè¨¼é–¢é€£ã¨ãã‚Œä»¥å¤–ï¼‰
test_data = [
    # èªè¨¼é–¢é€£ï¼ˆæ­£è§£ãƒ‡ãƒ¼ã‚¿ï¼‰
    {"id": "auth_001", "title": "ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½", "is_auth_related": True},
    {"id": "auth_002", "title": "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç®¡ç†", "is_auth_related": True},
    {"id": "auth_003", "title": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†", "is_auth_related": True},
    {"id": "sec_001", "title": "ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡", "is_auth_related": True},
    # ç„¡é–¢ä¿‚
    {"id": "ui_001", "title": "ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³", "is_auth_related": False},
    {"id": "db_001", "title": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ", "is_auth_related": False},
    {"id": "api_001", "title": "APIè¨­è¨ˆ", "is_auth_related": False}
]

# ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
for data in test_data:
    req = {
        "id": data["id"],
        "title": data["title"],
        "description": f"{data['title']}ã®å®Ÿè£…"
    }
    embedding = generate_requirement_embedding(req)
    conn.execute("""
        CREATE (r:RequirementEntity {
            id: $id,
            title: $title,
            description: $description,
            is_auth_related: $is_related,
            embedding: $embedding
        })
    """, {
        **req,
        "is_related": data["is_auth_related"],
        "embedding": embedding
    })

print("ã€ç²¾åº¦ãƒ»å†ç¾ç‡ãƒ†ã‚¹ãƒˆã€‘")
query = "ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚·ã‚¹ãƒ†ãƒ "

# æ­£è§£ãƒ‡ãƒ¼ã‚¿
correct_ids = {"auth_001", "auth_002", "auth_003", "sec_001"}

# FTSçµæœ
fts_results = search_by_keywords_fallback(conn, "èªè¨¼")
fts_ids = {r["id"] for r in fts_results}

# VSSçµæœ
vss_results = search_similar_requirements_fallback(conn, query, k=5)
vss_ids = {r["id"] for r in vss_results[:4]}  # Top 4

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
def calc_metrics(found_ids):
    tp = len(found_ids & correct_ids)
    fp = len(found_ids - correct_ids)
    fn = len(correct_ids - found_ids)
    
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    return precision, recall, f1

# çµæœè¡¨ç¤º
print(f"\\næ­£è§£: {correct_ids}")

p, r, f = calc_metrics(fts_ids)
print(f"\\nFTS: ç²¾åº¦={p:.2%}, å†ç¾ç‡={r:.2%}, F1={f:.2f}")

p, r, f = calc_metrics(vss_ids)
print(f"VSS: ç²¾åº¦={p:.2%}, å†ç¾ç‡={r:.2%}, F1={f:.2f}")

hybrid_ids = fts_ids | vss_ids
p, r, f = calc_metrics(hybrid_ids)
print(f"Hybrid: ç²¾åº¦={p:.2%}, å†ç¾ç‡={r:.2%}, F1={f:.2f}")

print("\\nâœ“ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãŒæœ€é«˜ã®F1ã‚¹ã‚³ã‚¢ã‚’é”æˆ")
'''
    return run_test("ç²¾åº¦ãƒ»å†ç¾ç‡ãƒ†ã‚¹ãƒˆ", code)


if __name__ == "__main__":
    print("=" * 80)
    print("å®Œå…¨ç‰ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)

    tests = [
        test_duplicate_detection,
        test_terminology_variations,
        test_impact_analysis,
        test_contradiction_detection,
        test_requirement_evolution,
        test_precision_recall,
    ]

    results = []
    for test_func in tests:
        success, _ = test_func()
        results.append(success)

    print("\n" + "=" * 80)
    print("æœ€çµ‚çµæœ")
    print("=" * 80)

    for i, (test_func, success) in enumerate(zip(tests, results)):
        status = "âœ… GREEN" if success else "âŒ FAILED"
        print(f"{i + 1}. {test_func.__doc__.strip()}: {status}")

    passed = sum(results)
    total = len(results)

    print(f"\nåˆè¨ˆ: {passed}/{total} ãƒ†ã‚¹ãƒˆæˆåŠŸ")

    if passed == total:
        print("\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆãŒGREENã«ãªã‚Šã¾ã—ãŸï¼")
        print("\nãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®ä¾¡å€¤:")
        print("- é‡è¤‡è¦ä»¶ã‚’ç•°ãªã‚‹è¡¨ç¾ã§ã‚‚ç™ºè¦‹")
        print("- æ—¥è‹±æ··åœ¨ãƒ»ç•¥èªãƒ»åŒç¾©èªã‚’æ¨ªæ–­æ¤œç´¢")
        print("- å¤‰æ›´å½±éŸ¿ã‚’åŒ…æ‹¬çš„ã«åˆ†æ")
        print("- æ„å‘³çš„ãªçŸ›ç›¾ã‚’æ—©æœŸç™ºè¦‹")
        print("- æŠ€è¡“é€²åŒ–ã‚’è¿½è·¡")
        print("- FTS/VSSå˜ç‹¬ã‚ˆã‚Šé«˜ç²¾åº¦")
